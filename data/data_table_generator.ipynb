{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data table generator for ID Mapping Service\n",
    "\n",
    "## Introduction\n",
    "This is a python script to generate data maping table for this GO service.\n",
    "\n",
    "To use this with the Docker Compose command, please export this as a standard python script. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from NCBI FTP server: FLY...\n",
      "Downloading from NCBI FTP server: HUMAN...\n",
      "Downloading from NCBI FTP server: ARATH...\n",
      "Downloading from NCBI FTP server: MOUSE...\n",
      "Downloading from NCBI FTP server: YEAST...\n"
     ]
    }
   ],
   "source": [
    "# Source data set builder for in-memory data table used in ID Mapper.\n",
    "import pandas as pd\n",
    "import json, urllib.request\n",
    "\n",
    "# Location of original data sets\n",
    "NCBI_FTP = \"ftp://ftp.ncbi.nih.gov/gene/DATA/GENE_INFO/\"\n",
    "UNI_FTP = \"ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/idmapping/by_organism/\"\n",
    "\n",
    "# From NCBI Gene\n",
    "NCBI_SOURCES = {\n",
    "    \"HUMAN\": NCBI_FTP + \"Mammalia/Homo_sapiens.gene_info.gz\",\n",
    "    \"YEAST\": NCBI_FTP + \"Fungi/Saccharomyces_cerevisiae.gene_info.gz\",\n",
    "    \"MOUSE\": NCBI_FTP + \"Mammalia/Mus_musculus.gene_info.gz\",\n",
    "    \"FLY\": NCBI_FTP + \"Invertebrates/Drosophila_melanogaster.gene_info.gz\",\n",
    "    \"ARATH\": NCBI_FTP + \"Plants/Arabidopsis_thaliana.gene_info.gz\"\n",
    "}\n",
    "\n",
    "# Uniprot ID Mapping\n",
    "UNIPROT_SOURCES = {\n",
    "    \"HUMAN\": UNI_FTP + \"HUMAN_9606_idmapping_selected.tab.gz\",\n",
    "    \"MOUSE\": UNI_FTP + \"MOUSE_10090_idmapping_selected.tab.gz\",\n",
    "    \"YEAST\": UNI_FTP + \"YEAST_559292_idmapping_selected.tab.gz\",\n",
    "    \"FLY\": UNI_FTP + \"DROME_7227_idmapping_selected.tab.gz\",\n",
    "    \"ARATH\": UNI_FTP + \"ARATH_3702_idmapping_selected.tab.gz\"\n",
    "}\n",
    "\n",
    "# Get all data sets from the FTP server\n",
    "NCBI_COLUMNS = [\"tax_id\", \"GeneID\", \"Symbol\", \"LocusTag\", \"Synonyms\", \"dbXrefs\", \"chromosome\", \"map_location\",\n",
    "                \"description\", \"type_of_gene\", \"Symbol_from_nomenclature_authority\", \"Full_name_from_nomenclature_authority\",\n",
    "                \"Nomenclature_status\", \"Other_designations\", \"Modification_date\"]\n",
    "\n",
    "UNIPROT_COLUMNS = ['UniProtKB-AC','UniProtKB-ID','GeneID','RefSeq','GI','PDB','GO','UniRef100','UniRef90',\n",
    "    'UniRef50','UniParc','PIR','NCBI-taxon','MIM','UniGene','PubMed','EMBL','EMBL-CDS',\n",
    "    'Ensembl','Ensembl_TRS','Ensembl_PRO','Additional PubMed']\n",
    "\n",
    "## Load NCBI data first.\n",
    "\n",
    "ncbi_map = {}\n",
    "\n",
    "for key in NCBI_SOURCES:\n",
    "    print(\"Downloading from NCBI FTP server: \" + key + \"...\")    \n",
    "    local_filename, headers = urllib.request.urlretrieve(NCBI_SOURCES[key])\n",
    "    ncbi_map[key] = pd.read_csv(local_filename, sep='\\t', low_memory=False, \n",
    "                             names=NCBI_COLUMNS, comment='#', compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from Uniprot FTP server: FLY...\n",
      "Downloading from Uniprot FTP server: HUMAN...\n",
      "Downloading from Uniprot FTP server: ARATH...\n",
      "Downloading from Uniprot FTP server: MOUSE...\n",
      "Downloading from Uniprot FTP server: YEAST...\n"
     ]
    }
   ],
   "source": [
    "# Load UNIPROT data next...\n",
    "uniprot_map = {}\n",
    "\n",
    "for key in UNIPROT_SOURCES:\n",
    "    print(\"Downloading from Uniprot FTP server: \" + key + \"...\")    \n",
    "    local_filename, headers = urllib.request.urlretrieve(UNIPROT_SOURCES[key])\n",
    "    uniprot_map[key] = pd.read_csv(local_filename, \n",
    "                     sep=\"\\t\", names=UNIPROT_COLUMNS, low_memory=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in ncbi_map:\n",
    "    ncbi_gene_info = ncbi_map[key]\n",
    "    ncbi_subset = ncbi_gene_info[[\"GeneID\", \"Symbol\", \"LocusTag\", \"Synonyms\", \"chromosome\", \"map_location\",\n",
    "                \"description\", \"Full_name_from_nomenclature_authority\"]].astype(str)\n",
    "    \n",
    "    # Merge and create new table\n",
    "    merged = pd.merge(uniprot_map[key], ncbi_subset , left_on=\"GeneID\", right_on=\"GeneID\", how=\"outer\")\n",
    "    # Drop unnecessary columns\n",
    "    df_final = merged.drop(\"Additional PubMed\", 1)\n",
    "    df_final = df_final.drop(\"NCBI-taxon\", 1)\n",
    "    df_final = df_final.drop(\"PubMed\", 1)\n",
    "    \n",
    "    # Create one mapping file / species\n",
    "    df_final.to_csv(\"./idmapping_\" + key.lower() +\".tsv\", sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
